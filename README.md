
## ðŸ“ Welcome to "Car Price Prediction - Geely Auto US Market Analysis" Project (Regression)

### Overview
This project addresses a regression problem using the **Geely Auto Car Data**. The goal is to build a model that can predict the car price for Geely Auto's strategic entry into the US market.

### Objectives
1.  **Data Loading & Inspection:** Load the dataset from Kaggle and perform initial inspection.
2.  **Exploratory Data Analysis (EDA):** Derive visuals to determine correlation between different features (Heatmap, Pie Charts, Box Plots, etc.).
3.  **Data Pre-Processing & Feature Engineering:** Handle missing values, outliers, and derive new features if necessary.
4.  **Encoding Features & Normalization:** Encode categorical features and scale numerical features.
5.  **Data Splitting:** Split your dataset randomly for training, validation, and testing.
6.  **Model Building & Training:** Apply linear regression and other models. Implement from scratch using matrix operations (normal equation, gradient descent) and compare with Scikit-Learn.
7.  **Regularization:** Apply L2 Regularization (Ridge Regression) and L1 Regularization (Lasso Regression). Try different regularization parameters & plot validation error vs. regularization parameter.
8.  **Feature Selection:** Select the features with high correlations to the target variable.
9.  **Model Evaluation:** Report Mean Square Error (MSE) and Mean Absolute Error (MAE) for all models.
10. **Results Analysis:** Add comments on the results and compare between the models.

### Dataset
**Name:** Car Price Prediction (Geely Auto)  
**Source:** [Car Price Prediction Dataset on Kaggle] --> (https://www.kaggle.com/datasets/hellbuoy/car-price-prediction)

**Target Variable:** `price` (Manufacturerâ€™s suggested retail price in USD)

### Key Steps
1.  Loading Dataset from Kaggle
2.  EDA (Exploratory Data Analysis) and Visualizing Correlations
3.  Data Pre-Processing (Handling Missing Values, Scaling)
4.  Encoding Categorical Features
5.  Obtaining Correlation with Target and Feature Selection
6.  Data Normalization
7.  Data Splitting (Training, Validation, Testing Sets)
8.  Model Building (Linear, Ridge, Lasso Regression from scratch and via Scikit-Learn)
9.  Training the Model and Hyperparameter Tuning
10. Model Evaluation using MSE, MAE, and RÂ² Score
